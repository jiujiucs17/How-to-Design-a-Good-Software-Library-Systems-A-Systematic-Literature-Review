{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a203ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import pybtex\n",
    "from tqdm import tqdm\n",
    "from pybtex.database import parse_file\n",
    "\n",
    "pybtex.errors.set_strict_mode(False)\n",
    "\n",
    "class BibData:\n",
    "    data_dicts: []\n",
    "    data_df: pd.DataFrame\n",
    "    # num_of_literature: int\n",
    "    path_to_data: str\n",
    "\n",
    "    def __init__(self, path_to_data: str, is_dir=True, show_log=False):\n",
    "        # path_to_data: String. should point to either a .bib file or a directory directly contains .bib files\n",
    "        # show_log: if set to true, will print the number of literature imported from each individual file\n",
    "        self.data_df = None\n",
    "        self.path_to_data = path_to_data\n",
    "        if not os.path.isdir(path_to_data) and is_dir:\n",
    "            print(\"Warning: A path to a single file is given, it's recommanded to set parameter \\\"is_dir\\\" to false.\")\n",
    "            is_dir = False\n",
    "\n",
    "        if is_dir:\n",
    "            self.data_dicts = self._dir_to_list(path_to_data, show_log)\n",
    "        else:\n",
    "            self.data_dicts = self._single_bib_to_list(path_to_data, show_log)\n",
    "        self.num_of_literature = len(self.data_dicts)\n",
    "        print(\"Imported \" + str(self.num_of_literature) + \" literature(s) from \\\"\" + path_to_data + \"\\\"\")\n",
    "\n",
    "    def _single_bib_to_list(self, file_path, show_log=False):\n",
    "        # get the reference details in one .bib file in the format of a list.\n",
    "        # reture format:\n",
    "        # a tuple contains two elements:\n",
    "        # 1st element: a list of lists contains names of the fields for each literature\n",
    "        # 2nd element: a list of lists contains data of the fields for each literature\n",
    "        entries_dicts = []\n",
    "\n",
    "        bibdata = parse_file(file_path)\n",
    "        for entry_key in bibdata.entries:\n",
    "            entry_fields = [\"entry_key\"]\n",
    "            entry_values = [entry_key]\n",
    "\n",
    "            for field in bibdata.entries[entry_key].fields:\n",
    "                entry_fields.append(str(field).lower())\n",
    "                if str(field) == \"doi\" and \"https://doi.org/\" in str(bibdata.entries[entry_key].fields[field]):\n",
    "                    entry_values.append(str(bibdata.entries[entry_key].fields[field])[16:])\n",
    "                else:\n",
    "                    entry_values.append(str(bibdata.entries[entry_key].fields[field]))\n",
    "            entry_dict = dict(zip(entry_fields, entry_values))\n",
    "\n",
    "            entries_dicts.append(entry_dict)\n",
    "        if show_log:\n",
    "            print(\"Imported \" + str(len(entries_fields)) + \" literature from \" + file_path)\n",
    "        return entries_dicts\n",
    "\n",
    "    def _dir_to_list(self, path, show_log=False):\n",
    "        # takes in a .bib file or a folder directly contains multiple .bib files as input\n",
    "        # return a list of single literature lists\n",
    "        dir_entries_dicts = []\n",
    "\n",
    "        files = os.listdir(dir_path)\n",
    "        file_num = len(files)\n",
    "        error_num = 0\n",
    "        for file in files:\n",
    "            try:\n",
    "                file_entries_dicts = self._single_bib_to_list(path + file)\n",
    "                dir_entries_dicts = dir_entries_dicts + file_entries_dicts\n",
    "                if show_log:\n",
    "                    print(\"Imported \" + str(len(file_entries_dicts)) + \" literature from \" + file)\n",
    "            except Exception as err:\n",
    "                print(\"Error occured when reading file \\\"\" + file + \"\\\". Message: \", err)\n",
    "                error_num += 1\n",
    "        print(\"\\n\\n-------------------------------------------------------\")\n",
    "        print(\n",
    "            \"Successfully read \" + str(file_num - error_num) + \" file(s), \" + str(error_num) + \" file(s) raised error\")\n",
    "        return dir_entries_dicts\n",
    "\n",
    "    def remove_duplication(self, fill_na=False, duplication_key=[], keep=\"first\", internal_call=False):\n",
    "        if self.data_df is None:\n",
    "            print(\"DataFrame is never generated, will generate a DataFrame first\")\n",
    "            self.to_DataFrame(True, duplication_key, keep)\n",
    "        else:\n",
    "            if fill_na:\n",
    "                print(\"non values:\")\n",
    "                print(\"doi: \", bibdata.data_df[\"doi\"].isnull().sum(), \n",
    "                      \"\\nurl:\", bibdata.data_df[\"url\"].isnull().sum(), \n",
    "                      \"\\ntitle:\", bibdata.data_df[\"title\"].isnull().sum(), \n",
    "                      \"\\nabstract:\", bibdata.data_df[\"abstract\"].isnull().sum())\n",
    "                bibdata.data_df[\"doi\"] = bibdata.data_df[\"doi\"].fillna(bibdata.data_df[\"url\"])\n",
    "                bibdata.data_df[\"doi\"] = bibdata.data_df[\"doi\"].fillna(bibdata.data_df[\"title\"])\n",
    "                bibdata.data_df[\"doi\"] = bibdata.data_df[\"doi\"].fillna(bibdata.data_df[\"abstract\"])\n",
    "                bibdata.data_df[\"abstract\"] = bibdata.data_df[\"abstract\"].fillna(bibdata.data_df[\"title\"])\n",
    "                bibdata.data_df[\"url\"] = bibdata.data_df[\"url\"].fillna(bibdata.data_df[\"doi\"])\n",
    "                print(\"\\nafter filling, non values:\")\n",
    "                print(\"doi: \", bibdata.data_df[\"doi\"].isnull().sum(), \n",
    "                      \"\\nurl:\", bibdata.data_df[\"url\"].isnull().sum(), \n",
    "                      \"\\ntitle:\", bibdata.data_df[\"title\"].isnull().sum(), \n",
    "                      \"\\nabstract:\", bibdata.data_df[\"abstract\"].isnull().sum())\n",
    "            if internal_call==False:\n",
    "                print(\"\\n\\n-----------------DUPLICATION REMOVAL-------------------\")\n",
    "            pre_rm_dup = self.data_df.shape[0]\n",
    "            if duplication_key == []:\n",
    "                self.data_df = self.data_df.drop_duplicates(keep=keep)\n",
    "            elif len(duplication_key)==1:\n",
    "                self.data_df = self.data_df.drop_duplicates(keep=keep, subset=duplication_key)\n",
    "            else:\n",
    "                for key in duplication_key:\n",
    "                    self.remove_duplication(duplication_key=[key], internal_call=True)\n",
    "                 \n",
    "            if internal_call==False:\n",
    "                print(\"\\n\\nSummary:\")\n",
    "            print(\"key for duplication detection: \\\"\", duplication_key, \"\\\"\")\n",
    "            print(\"before duplication removal: \" + str(pre_rm_dup))\n",
    "            print(\"after duplication removal: \" + str(self.data_df.shape[0]))\n",
    "            print(\"removed records: \" + str(pre_rm_dup - self.data_df.shape[0])+\"\\n\")\n",
    "            # self.data_df = self.data_df.reset_index()\n",
    "        return\n",
    "\n",
    "    def to_DataFrame(self, remove_duplicate=False, fill_na=False, duplication_key=\"doi\", keep=\"first\"):\n",
    "        if self.data_df is None:\n",
    "            columns_labels = []\n",
    "            for entry_dictionary in tqdm(self.data_dicts, desc=\"Collecting Labels\"):\n",
    "                keys = list(entry_dictionary.keys())\n",
    "                for key in keys:\n",
    "                    if key not in columns_labels:\n",
    "                        columns_labels.append(key)\n",
    "            print(str(len(columns_labels)) + \" labels are collected.\")\n",
    "\n",
    "            bib_df = pd.DataFrame(columns=columns_labels)\n",
    "            for entry_dictionary in tqdm(self.data_dicts, desc=\"Filling in Data\"):\n",
    "                entry_df = pd.DataFrame(entry_dictionary, index=[0])\n",
    "                bib_df = pd.concat([bib_df, entry_df], join=\"outer\")\n",
    "            bib_df = bib_df.reset_index()\n",
    "\n",
    "            self.data_df = bib_df\n",
    "\n",
    "            if remove_duplicate:\n",
    "                self.remove_duplication(fill_na, duplication_key, keep)\n",
    "\n",
    "            return self.data_df\n",
    "        else:\n",
    "            return self.data_df\n",
    "\n",
    "    def to_excel(self, folder_path=\"\"):\n",
    "        if self.data_df is None:\n",
    "            print(\"DataFrame is never generated, will generate a DataFrame first\")\n",
    "            self.to_DataFrame()\n",
    "            self.data_df.to_excel(folder_path + \"BibDataOutput.xlsx\")\n",
    "        else:\n",
    "            self.data_df.to_excel(folder_path + \"BibDataOutput.xlsx\")\n",
    "        print(str(self.data_df.shape[0]) + \" records are output to\\\"\"+folder_path + \"BibDataOutput.xlsx\\\"\")\n",
    "        return\n",
    "\n",
    "    def record_num(self):\n",
    "        return self.data_df.shape[0]\n",
    "\n",
    "    def data_source(self):\n",
    "        return self.path_to_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4963e666",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: repeated bibliograhpy entry: GARCIA198851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occured when reading file \"springerlink.txt\". Message:  plugin pybtex.database.input.suffixes for suffix .txt not found\n",
      "Error occured when reading file \".DS_Store\". Message:  plugin pybtex.database.input.suffixes. not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: repeated bibliograhpy entry: NoAuthor2022\n",
      "WARNING: repeated bibliograhpy entry: NoAuthor2019\n",
      "WARNING: repeated bibliograhpy entry: Chisnall2017569\n",
      "WARNING: repeated bibliograhpy entry: Churchill2017313\n",
      "WARNING: repeated bibliograhpy entry: Dagand2016298\n",
      "WARNING: repeated bibliograhpy entry: Lee2015\n",
      "WARNING: repeated bibliograhpy entry: NoAuthor2014\n",
      "WARNING: repeated bibliograhpy entry: NoAuthor2014\n",
      "WARNING: repeated bibliograhpy entry: NoAuthor2013\n",
      "WARNING: repeated bibliograhpy entry: Pattabiraman2008219\n",
      "WARNING: repeated bibliograhpy entry: Ardimento2008357\n",
      "WARNING: repeated bibliograhpy entry: NoAuthor2007\n",
      "WARNING: repeated bibliograhpy entry: NoAuthor2007\n",
      "WARNING: repeated bibliograhpy entry: NoAuthor2007\n",
      "WARNING: repeated bibliograhpy entry: NoAuthor2005\n",
      "WARNING: repeated bibliograhpy entry: NoAuthor2005\n",
      "WARNING: repeated bibliograhpy entry: NoAuthor2005\n",
      "WARNING: repeated bibliograhpy entry: NoAuthor1997\n",
      "WARNING: repeated bibliograhpy entry: DYMSCHIZ1979245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occured when reading file \"SearchResults2.csv\". Message:  plugin pybtex.database.input.suffixes for suffix .csv not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: repeated bibliograhpy entry: HORVAI198543\n",
      "WARNING: repeated bibliograhpy entry: GARCIA198851\n",
      "WARNING: repeated bibliograhpy entry: PILLMANN1980189\n",
      "WARNING: repeated bibliograhpy entry: PILLMANN1980189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occured when reading file \"SearchResults1-2.csv\". Message:  plugin pybtex.database.input.suffixes for suffix .csv not found\n",
      "Error occured when reading file \"SearchResults1-1.csv\". Message:  plugin pybtex.database.input.suffixes for suffix .csv not found\n",
      "Error occured when reading file \"springerlink2.txt\". Message:  plugin pybtex.database.input.suffixes for suffix .txt not found\n",
      "Error occured when reading file \"springerlink1-2.txt\". Message:  plugin pybtex.database.input.suffixes for suffix .txt not found\n",
      "Error occured when reading file \"springerlink1-1.txt\". Message:  plugin pybtex.database.input.suffixes for suffix .txt not found\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "Successfully read 37 file(s), 8 file(s) raised error\n",
      "Imported 5438 literature(s) from \"data/refined_search_results/\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting Labels: 100%|████████████████| 5438/5438 [00:00<00:00, 767863.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 labels are collected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filling in Data: 100%|█████████████████████| 5438/5438 [00:21<00:00, 254.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non values:\n",
      "doi:  511 \n",
      "url: 2440 \n",
      "title: 0 \n",
      "abstract: 7\n",
      "\n",
      "after filling, non values:\n",
      "doi:  0 \n",
      "url: 0 \n",
      "title: 0 \n",
      "abstract: 0\n",
      "\n",
      "\n",
      "-----------------DUPLICATION REMOVAL-------------------\n",
      "key for duplication detection: \" ['doi'] \"\n",
      "before duplication removal: 5438\n",
      "after duplication removal: 4751\n",
      "removed records: 687\n",
      "\n",
      "key for duplication detection: \" ['url'] \"\n",
      "before duplication removal: 4751\n",
      "after duplication removal: 4751\n",
      "removed records: 0\n",
      "\n",
      "key for duplication detection: \" ['title'] \"\n",
      "before duplication removal: 4751\n",
      "after duplication removal: 4659\n",
      "removed records: 92\n",
      "\n",
      "key for duplication detection: \" ['abstract'] \"\n",
      "before duplication removal: 4659\n",
      "after duplication removal: 4619\n",
      "removed records: 40\n",
      "\n",
      "key for duplication detection: \" ['entry_key'] \"\n",
      "before duplication removal: 4619\n",
      "after duplication removal: 4614\n",
      "removed records: 5\n",
      "\n",
      "\n",
      "\n",
      "Summary:\n",
      "key for duplication detection: \" ['doi', 'url', 'title', 'abstract', 'entry_key'] \"\n",
      "before duplication removal: 5438\n",
      "after duplication removal: 4614\n",
      "removed records: 824\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"data/refined_search_results/\"\n",
    "file_path = \"data/references.bib\"\n",
    "bibdata = BibData(dir_path)\n",
    "bibdata.to_DataFrame()\n",
    "bibdata.remove_duplication(fill_na=True, duplication_key=[\"doi\", \"url\", \"title\", \"abstract\", \"entry_key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f03f0c1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4614 records are output to\"BibDataOutput.xlsx\"\n"
     ]
    }
   ],
   "source": [
    "bibdata.to_excel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6837470c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/refined_search_results/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bibdata.record_num()\n",
    "bibdata.data_source()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
